{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5200c484",
   "metadata": {},
   "source": [
    "## **PREPARE THE DATASETS FOR TRAINING DECISION TREES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e8ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e85af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL SETTINGS\n",
    "WINDOW_MAIN = 20      # janela longa (20 ciclos)\n",
    "WINDOW_TREND = 5      # janela curta (5 ciclos)\n",
    "RUL_THRESHOLD = 30    # limite para \"falha em breve\"\n",
    "\n",
    "# NOMEANDO AS COLUNAS DO DATAFRAME\n",
    "op_cols = [f\"op_setting_{i}\" for i in range(1, 4)]\n",
    "sensor_cols = [f\"sensor_{i}\" for i in range(1, 22)]\n",
    "base_cols = [\"id\", \"cycle\"] + op_cols + sensor_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2149e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. READING THE .TXT FILES\n",
    "\n",
    "# train_FD001: \n",
    "df_train_raw = pd.read_csv(\"train_FD001.txt\", delim_whitespace=True, header=None)\n",
    "df_train_raw.columns = base_cols\n",
    "\n",
    "# test_FD001: \n",
    "df_test_raw = pd.read_csv(\"test_FD001.txt\",delim_whitespace=True,header=None)\n",
    "df_test_raw.columns = base_cols\n",
    "\n",
    "# RUL_FD001:\n",
    "df_rul_final = pd.read_csv(\"RUL_FD001.txt\",header=None,names=[\"RUL_end\"])\n",
    "test_engine_ids_sorted = df_test_raw[\"id\"].unique()\n",
    "test_engine_ids_sorted.sort()\n",
    "df_rul_final[\"id\"] = test_engine_ids_sorted\n",
    "\n",
    "df_rul_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acb3769",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. CALCULATION OF RUL IN TRAINING\n",
    "# RUL = max_cycle - atual_cycle\n",
    "max_cycle_per_id = df_train_raw.groupby(\"id\")[\"cycle\"].transform(\"max\")\n",
    "df_train_raw[\"RUL\"] = max_cycle_per_id - df_train_raw[\"cycle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3cf0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. CREATE BINARY LABEL fail_soon IN TRAINING\n",
    "# fail_soon = 1 se RUL <= 30, else 0\n",
    "df_train_raw[\"fail_soon\"] = (df_train_raw[\"RUL\"] <= RUL_THRESHOLD).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. FUNCTION TO GENERATE WINDOW-BASED FEATURES\n",
    "## mean, standard deviation, min, and max of each sensor over the last 20 cycles\n",
    "## short-term trend: current value − mean of the last 5 cycles\n",
    "\n",
    "def make_features_for_engine(df_engine):\n",
    "    df_engine = df_engine.sort_values(\"cycle\").copy()\n",
    "\n",
    "    # Rolling window of 20 cycles for each sensor\n",
    "    roll_long = df_engine[sensor_cols].rolling(window=WINDOW_MAIN, min_periods=1)\n",
    "\n",
    "    feat_mean20 = roll_long.mean().add_suffix(\"_mean20\")\n",
    "    feat_std20  = roll_long.std(ddof=0).add_suffix(\"_std20\")\n",
    "    feat_min20  = roll_long.min().add_suffix(\"_min20\")\n",
    "    feat_max20  = roll_long.max().add_suffix(\"_max20\")\n",
    "\n",
    "    # Short-term trend: current value − mean of the last 5 cycles\n",
    "    roll_short_mean = df_engine[sensor_cols].rolling(window=WINDOW_TREND, min_periods=1).mean()\n",
    "    feat_trend5 = (df_engine[sensor_cols] - roll_short_mean).add_suffix(\"_trend5\")\n",
    "\n",
    "    # Combine everything\n",
    "    out = pd.concat([\n",
    "        df_engine[[\"id\", \"cycle\", \"RUL\", \"fail_soon\"] + op_cols],\n",
    "        feat_mean20,\n",
    "        feat_std20,\n",
    "        feat_min20,\n",
    "        feat_max20,\n",
    "        feat_trend5,\n",
    "    ], axis=1)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aaa56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. APPLY THE FUNCTION TO ALL TRAINING ENGINES\n",
    "df_train_feat = (\n",
    "    df_train_raw\n",
    "    .groupby(\"id\", group_keys=False)\n",
    "    .apply(make_features_for_engine)\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aa76bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saulo\\AppData\\Local\\Temp\\ipykernel_23780\\1210272573.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(make_features_for_engine)\n"
     ]
    }
   ],
   "source": [
    "## 6. RUL IN TEST AND fail_soon LABEL\n",
    "# RUL estimate per row assuming RUL_end at the last cycle and calculating backwards\n",
    "\n",
    "# Maximum observed cycle for each engine in the test set\n",
    "max_cycle_test = df_test_raw.groupby(\"id\")[\"cycle\"].transform(\"max\")\n",
    "df_test_raw[\"cycle_max\"] = max_cycle_test\n",
    "\n",
    "rul_map = dict(zip(df_rul_final[\"id\"], df_rul_final[\"RUL_end\"]))\n",
    "\n",
    "# For each row of each engine in the test set::\n",
    "# RUL(line) = engine_RUL_end + (engine_cycle_max - current_cycle)\n",
    "df_test_raw[\"RUL\"] = df_test_raw.apply(\n",
    "    lambda row: rul_map[row[\"id\"]] + (row[\"cycle_max\"] - row[\"cycle\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_test_raw[\"fail_soon\"] = (df_test_raw[\"RUL\"] <= RUL_THRESHOLD).astype(int)\n",
    "\n",
    "# Generate features per engine in the test set\n",
    "df_test_feat = (\n",
    "    df_test_raw\n",
    "    .groupby(\"id\", group_keys=False)\n",
    "    .apply(make_features_for_engine)\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f0fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. SAVING DATA .CSV\n",
    "df_train_feat.to_csv(\"train_features_fd001.csv\", index=False)\n",
    "df_test_feat.to_csv(\"test_features_fd001.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
